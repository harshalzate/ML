{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyP4m/C0ij2XJP+7cfdHMktH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from sklearn.datasets import make_regression\n","import pandas as pd\n","import numpy as np\n","X,y= make_regression(n_samples=100,n_features=2,noise=10,random_state=42)\n","from sklearn.model_selection import train_test_split\n","X_train,x_test,Y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"],"metadata":{"id":"ZQCBJLuSMUn-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1. varience threshold\n","from sklearn.feature_selection import VarianceThreshold\n","selector=VarianceThreshold(threshold=0.90)\n","selector.fit(X_train) # calculates the varience of each feature\n","selector.get_support() # gives which features have higher threshold\n","X_train_Transform = selector.transform(X_train) # select those features only with theier value"],"metadata":{"id":"T1zIsawfM88N"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1AqrHzILL19i"},"outputs":[],"source":["# 3 Correlation\n","corr_matrix=pd.DataFrame(X_train).corr()\n","columns = corr_matrix.columns\n","columns_to_drop = []\n","for i in range(len(columns)):\n","    for j in range(i + 1, len(columns)):\n","        # Access the cell of the DataFrame\n","        if corr_matrix.loc[columns[i], columns[j]] > 0.95:\n","            columns_to_drop.append(columns[j])\n","\n","print(len(columns_to_drop))"]},{"cell_type":"code","source":["# 4 Annova\n","from sklearn.feature_selection import f_classif\n","from sklearn.feature_selection import SelectKBest\n","\n","sel = SelectKBest(f_classif, k=100).fit(X_train, y_train)\n","X_train.columns[sel.get_support()]"],"metadata":{"id":"iN2BqECQMm-N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 5 Chi-square Test\n","titanic = pd.read_csv('/kaggle/input/titanic/train.csv')[['Pclass','Sex','SibSp','Parch','Embarked','Survived']]\n","titanic.head()\n","ct = pd.crosstab(titanic['Survived'],titanic['Sex'],margins=True)\n","from scipy.stats import chi2_contingency\n","chi2_contingency(ct)\n","score = []\n","for feature in titanic.columns[:-1]:\n","    # create contingency table\n","    ct = pd.crosstab(titanic['Survived'], titanic[feature])\n","    # chi_test\n","    p_value = chi2_contingency(ct)[1]\n","    score.append(p_value)\n","\n","    pd.Series(score, index=titanic.columns[:-1]).sort_values(ascending=True).plot(kind='bar')\n","\n","# one more method\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.feature_selection import chi2\n","import matplotlib.pyplot as plt\n","\n","# assuming titanic is your DataFrame and 'Survived' is the target column\n","\n","# Encode categorical variables\n","le = LabelEncoder()\n","titanic_encoded = titanic.apply(le.fit_transform)\n","\n","X = titanic_encoded.drop('Survived', axis=1)\n","y = titanic_encoded['Survived']\n","\n","# Calculate chi-squared stats\n","chi_scores = chi2(X, y)\n","\n","# chi_scores[1] are the p-values of each feature.\n","p_values = pd.Series(chi_scores[1], index = X.columns)\n","p_values.sort_values(inplace = True)\n","\n","# Plotting the p-values\n","p_values.plot.bar()\n","\n","plt.title('Chi-square test - P-values')\n","plt.xlabel('Feature')\n","plt.ylabel('P-value')\n","\n","plt.show()"],"metadata":{"id":"1hVHfevdQeD2"},"execution_count":null,"outputs":[]}]}